{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# opencv 캠 캡쳐\n",
    "https://zzsza.github.io/data/2018/01/23/opencv-1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "index = 0\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3,1280) #CV_CAP_PROP_FRAME_WIDTH\n",
    "cam.set(4,720) #CV_CAP_PROP_FRAME_HEIGHT\n",
    "#cam.set(5,0) #CV_CAP_PROP_FPS\n",
    " \n",
    "while True:\n",
    "    ret_val, img = cam.read() # 캠 이미지 불러오기\n",
    "    #ret, jpeg = cv2.imencode('.jpg', image)\n",
    " \n",
    "    cv2.imshow(\"Cam Viewer\",img) # 불러온 이미지 출력하기\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break  # esc to quit\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Detection ( 얼굴 탐지 )\n",
    "    - 사진에서 얼굴의 위치가 어디인지 알아내는 방법\n",
    "    - 한 프레임에서 얼굴을 찾음\n",
    "\n",
    "## Face Tracking ( 얼굴 추적 )\n",
    "    - 동영상에서 얼굴 탐지를 한번 하고 추적 알고리즘을 통해 따라다니게 하는 방법\n",
    "\n",
    "## Face Recognition ( 얼굴 인식 )\n",
    "    - 사진을 이미 알고있는 상태에서 새로운 사진에서 누가 알고있는 인물인지 알아내는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 얼굴 탐지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 얼굴 탐지\n",
    "import cv2, dlib, sys\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def faceDetect():\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')               \n",
    "    \n",
    "    try:\n",
    "        # 이면 캠\n",
    "        cap = cv2.VideoCapture(0)\n",
    "    except:\n",
    "        print('카메라 로딩 실패')\n",
    "        return\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            return\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 2, 0, (10,10))\n",
    "        \n",
    "        for(x,y,w,h) in faces:\n",
    "            cv2.rectangle(frame, (x,y), (x+w, y+h), (255,0,0), 3,4,0)\n",
    "            \n",
    "        frame = cv2.resize(frame.copy(), (800,700))\n",
    "            \n",
    "        cv2.imshow('frame', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) == 27:\n",
    "            cap.release()\n",
    "            cv2.destroyWindow('frame')\n",
    "            break;\n",
    "        \n",
    "faceDetect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 얼굴 및 눈 탐지, 랜드마크 찍기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, dlib, sys\n",
    "import numpy as np\n",
    "import PIL as ImageGrab\n",
    "import time\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')               \n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "\n",
    "def faceDetect():\n",
    "    try:\n",
    "        # 이면 캠\n",
    "        cap = cv2.VideoCapture(0)\n",
    "    except:\n",
    "        print('카메라 로딩 실패')\n",
    "        return\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            return\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 2, 0, (10,10))\n",
    "        \n",
    "        for(x,y,w,h) in faces:\n",
    "            cv2.rectangle(frame, (x,y), (x+w, y+h), (255,0,0), 3,4,0)\n",
    "            face_gray = gray[y:y+h, x:x+w]\n",
    "            face_color = frame[y: y+h, x:x+w]\n",
    "            \n",
    "            # landmark\n",
    "            dlib_rect = dlib.rectangle(int(x), int(y), int(x+w), int(y+h))\n",
    "            landmarks = np.matrix([[p.x, p.y] for p in predictor(frame, dlib_rect).parts()])\n",
    "            landmarks_display = landmarks[0:68]\n",
    "            \n",
    "            eyes = eye_cascade.detectMultiScale(face_gray, 1.1, 3)\n",
    "            \n",
    "            for(ex, ey, ew, eh) in eyes:\n",
    "                cv2.rectangle(face_color, (ex, ey), (ex + ew, ey + eh), (0,255,0), 2)\n",
    "                \n",
    "            for idx, point in enumerate(landmarks_display):\n",
    "                pos = (point[0, 0], point[0, 1])\n",
    "                cv2.circle(frame, pos, 2, color=(0,255,255), thickness = -1)\n",
    "        \n",
    "        frame = cv2.flip(frame,1, 0)\n",
    "        #frame = cv2.resize(frame.copy(), (800,700))\n",
    "            \n",
    "        cv2.imshow('frame', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) == 27:\n",
    "            cap.release()\n",
    "            cv2.destroyWindow('frame')\n",
    "            break;\n",
    "        \n",
    "faceDetect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 랜드마크만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, dlib, sys\n",
    "import numpy as np\n",
    "import PIL as ImageGrab\n",
    "import time\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')               \n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "\n",
    "def faceDetect():\n",
    "    try:\n",
    "        # 이면 캠\n",
    "        cap = cv2.VideoCapture(0)\n",
    "    except:\n",
    "        print('카메라 로딩 실패')\n",
    "        return\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            return\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 2, 0, (10,10))\n",
    "        \n",
    "        for(x,y,w,h) in faces:\n",
    "            # landmark\n",
    "            dlib_rect = dlib.rectangle(int(x), int(y), int(x+w), int(y+h))\n",
    "            landmarks = np.matrix([[p.x, p.y] for p in predictor(frame, dlib_rect).parts()])\n",
    "            landmarks_display = landmarks[0:68]\n",
    "                \n",
    "            for idx, point in enumerate(landmarks_display):\n",
    "                pos = (point[0, 0], point[0, 1])\n",
    "                cv2.circle(frame, pos, 2, color=(0,255,255), thickness = -1)\n",
    "        \n",
    "        frame = cv2.flip(frame,1, 0)\n",
    "        #frame = cv2.resize(frame.copy(), (800,700))\n",
    "            \n",
    "        cv2.imshow('frame', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) == 27:\n",
    "            cap.release()\n",
    "            cv2.destroyWindow('frame')\n",
    "            break;\n",
    "        \n",
    "faceDetect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 화면 캡처 하면서 얼굴 인식해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, dlib, sys\n",
    "import numpy as np\n",
    "import pyscreenshot as ImageGrab\n",
    "import time\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')               \n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "\n",
    "def faceDetect():\n",
    "    \n",
    "    while True:\n",
    "        image = ImageGrab.grab()\n",
    "        frame = np.array(image)\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 2, 0, (10,10))\n",
    "        \n",
    "        for(x,y,w,h) in faces:\n",
    "            cv2.rectangle(frame, (x,y), (x+w, y+h), (255,0,0), 3,4,0)\n",
    "            face_gray = gray[y:y+h, x:x+w]\n",
    "            face_color = frame[y: y+h, x:x+w]\n",
    "            \n",
    "            # landmark\n",
    "            dlib_rect = dlib.rectangle(int(x), int(y), int(x+w), int(y+h))\n",
    "            landmarks = np.matrix([[p.x, p.y] for p in predictor(frame, dlib_rect).parts()])\n",
    "            landmarks_display = landmarks[0:68]\n",
    "            \n",
    "            eyes = eye_cascade.detectMultiScale(face_gray, 1.1, 3)\n",
    "            \n",
    "            for(ex, ey, ew, eh) in eyes:\n",
    "                cv2.rectangle(face_color, (ex, ey), (ex + ew, ey + eh), (0,255,0), 2)\n",
    "                \n",
    "            for idx, point in enumerate(landmarks_display):\n",
    "                pos = (point[0, 0], point[0, 1])\n",
    "                cv2.circle(frame, pos, 2, color=(0,255,255), thickness = -1)\n",
    "        \n",
    "        #frame = cv2.flip(frame,1, 0)\n",
    "        #frame = cv2.resize(frame.copy(), (800,700))\n",
    "            \n",
    "        cv2.imshow('frame', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) == 27:\n",
    "            cap.release()\n",
    "            cv2.destroyWindow('frame')\n",
    "            break;\n",
    "        \n",
    "faceDetect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function str.count>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
